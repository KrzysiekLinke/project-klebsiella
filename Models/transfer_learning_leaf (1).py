# -*- coding: utf-8 -*-
"""Transfer-learning-leaf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SUWa0Fb_1RWBDiaCGXT7CA1viPEMCs_q
"""

! git clone https://github.com/KrzysiekLinke/leaf-datasets.git

! ls leaf-datasets/krzys/

# Commented out IPython magic to ensure Python compatibility.
import glob
import numpy as np
import matplotlib.pyplot as plt
import os
import shutil
from PIL import Image
np.random.seed(42)
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img
# %matplotlib inline

IMG_DIM = (224, 224)

validation_files = glob.glob('leaf-datasets/krzys/validation_data/*')
validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]
validation_imgs = np.array(validation_imgs)
validation_labels = [fn.split('/')[3].split('.')[0].strip() for fn in validation_files]

print( 'Validation dataset shape:', validation_imgs.shape)

train_files = glob.glob('leaf-datasets/krzys/training_data/*')
train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]
train_imgs = np.array(train_imgs)
train_labels = [fn.split('/')[3].split('.')[0].strip() for fn in train_files]

print('Train dataset shape:', train_imgs.shape)

train_imgs_scaled = train_imgs.astype('float32')
validation_imgs_scaled  = validation_imgs.astype('float32')
train_imgs_scaled /= 255
validation_imgs_scaled /= 255

print(train_imgs[0].shape)
array_to_img(train_imgs[0])

batch_size = 30
num_classes = 2
epochs = 30
input_shape = (224, 224, 3)

# encode text category labels
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
le.fit(train_labels)
train_labels_enc = le.transform(train_labels)
validation_labels_enc = le.transform(validation_labels)

print(train_labels[1495:1505], train_labels_enc[1495:1505])

"""# VGG16 transfer learning"""

from keras.applications import vgg16
from keras.models import Model
import keras

vgg_16 = vgg16.VGG16(include_top=False, weights='imagenet', 
                                     input_shape=input_shape)

output = vgg_16.layers[-1].output
output = keras.layers.Flatten()(output)
vgg16_model = Model(vgg_16.input, output)

vgg16_model.trainable = False
for layer in vgg16_model.layers:
    layer.trainable = False
    
import pandas as pd
pd.set_option('max_colwidth', -1)
layers = [(layer, layer.name, layer.trainable) for layer in vgg16_model.layers]
pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])

train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,
                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, 
                                   horizontal_flip=True, fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)
val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)

img_id = 2595
healthy_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],
                                   batch_size=1)
healthy = [next(healthy_generator) for i in range(0,5)]
fig, ax = plt.subplots(1,5, figsize=(16, 6))
print('Labels:', [item[1][0] for item in healthy])
l = [ax[i].imshow(healthy[i][0][0]) for i in range(0,5)]

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

modelVGG16 = Sequential()
modelVGG16.add(vgg16_model)
modelVGG16.add(Dense(512, activation='relu', input_dim=input_shape))
modelVGG16.add(Dropout(0.3))
modelVGG16.add(Dense(512, activation='relu'))
modelVGG16.add(Dropout(0.3))
modelVGG16.add(Dense(1, activation='sigmoid'))

modelVGG16.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['accuracy'])
              
history = modelVGG16.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=val_generator, validation_steps=100, 
                              verbose=1)

modelVGG16.save('vgg16_model_new.h5')

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive 
from google.colab import auth 
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()                       
drive = GoogleDrive(gauth)
model_file = drive.CreateFile({'title' : 'vgg16_model_final.h5'})                       
model_file.SetContentFile('vgg16_model_new.h5')                       
model_file.Upload()

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
t = f.suptitle('Pre trained VGG16 transfer learning - performance', fontsize=12)
f.subplots_adjust(top=0.85, wspace=0.3)

epoch_list = list(range(1,101))
ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')
ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')
ax1.set_xticks(np.arange(0, 101, 5))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
l1 = ax1.legend(loc="best")

ax2.plot(epoch_list, history.history['loss'], label='Train Loss')
ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(0, 100, 5))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

# Commented out IPython magic to ensure Python compatibility.
# load dependencies
import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img, img_to_array, array_to_img
from keras.models import load_model
import model_evaluation_utils as meu
# %matplotlib inline

# load saved models
vgg16_model = load_model('vgg16_model_new.h5')

# load other configurations
IMG_DIM = (224, 224)
input_shape = (224, 224, 3)
num2class_label_transformer = lambda l: ['healthy' if x == 0 else 'infected' for x in l]
class2num_label_transformer = lambda l: [0 if x == 'healthy' else 1 for x in l]

test_files = glob.glob('leaf-datasets/krzys/test_data/*')
test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]
test_imgs = np.array(test_imgs)
test_labels = [fn.split('/')[2].split('.')[0].strip() for fn in test_files]

test_imgs_scaled = test_imgs.astype('float32')
test_imgs_scaled /= 255
test_labels_enc = class2num_label_transformer(test_labels)

print('Test dataset shape:', test_imgs.shape)
print(test_labels[0:5], test_labels_enc[0:5])

test_labels = [fn.split('/')[3].split('.')[0].strip() for fn in test_files]

test_imgs_scaled = test_imgs.astype('float32')
test_imgs_scaled /= 255
test_labels_enc = class2num_label_transformer(test_labels)

print('Test dataset shape:', test_imgs.shape)
print(test_labels[0:5], test_labels_enc[0:5])

"""## VGG16"""

predictions = vgg16_model.predict_classes(test_imgs_scaled, verbose=0)
predictions = num2class_label_transformer(predictions)
meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, 
                                      classes=list(set(test_labels)))